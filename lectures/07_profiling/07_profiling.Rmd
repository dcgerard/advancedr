---
title: "Profiling and Benchmarking Performance"
author: "David Gerard"
date: "`r Sys.Date()`"
output:  
  html_document:
    toc: true
    toc_depth: 4
    toc_float: false
    highlight: pygments
urlcolor: "blue"
bibliography: "07_bib.bib"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo       = TRUE, 
                      fig.align  = "center",
                      fig.height = 3, fig.width = 4)
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

# Learning Objectives

- Chapter 23 of [Advanced R](https://adv-r.hadley.nz/).
- Profiling and microbenchmarking.

# Motivation

- Before you get started, the **two rules of software optimization** are [@jackson1975principles]:
    1. Don't do it.
    2. Don’t do it yet (for experts only).

- If you try to optimize too soon, you will usually end up wasting more time than you save. Your code will usually become clunky and harder to maintain.

- You should only start optimizing your code after:
    1. You have a perfectly clear and unoptimized solution.
    2. You have profiled your code.

- It is hard to tell what code is fast versus slow, so we have tools to measure this.

- **Profiling** is measuring the run-time on each line of code.

- Use `{profvis}` for profiling:

    ```{r}
    library(profvis)
    ```

- **Microbenchmarking** is comparing performance between different pieces of code.

- Use `{bench}` for microbenchmarking:

    ```{r}
    library(bench)
    ```

- When you go back to optimize, only work on the slowest parts.

# Profiling a Function

- Place a function call inside `profvis::profvis()` to profile the function.

- It is better for the profiler if you source the code first (it gives you better graphics). So I place the following code in "07_example.R". 

    ```{r, eval = FALSE}
    f <- function() {
      pause(0.1)
      g()
      h()
    }
    g <- function() {
      pause(0.1)
      h()
    }
    h <- function() {
      pause(0.1)
    }
    profvis(f())
    ```
    
    Then use `source()` on it before placing the function in `profvis()`.
    
    ```{r, eval = FALSE}
    source("./07_example.R")
    profvis(f())
    ```

- The pane that pops up looks like this:    

    ```{r, echo = FALSE}
    knitr::include_graphics(path = "./07_figs/profvis_view.png")
    ```

- The top pane is a bar-graph for the execution time for each line of code. 

- This doesn't tell you why some lines are slower, e.g. `h()` is called twice, so that's why it is twice as long as other lines.

- The bottom pane is called a **flame graph**.
    - $x$ axis is total time.
    - Top of $y$ axis is what is currently being run.
    - The bars beneath the top are the ancestry.
    - From left to right we have 
        i. `pause()` running in `f()`.
        ii. `pause()` running in `g()` running in `f()`.
        iii. `pause()` running in `h()` running in `g()` running in `f()`.
        iv. `pause()` running in `h()` running `f()`.

- So if we saw this, we would try speeding up `h()` since it takes up half the amount of total time, so we can probably have the most speed improvements by working on that.

- The **data tab** has the same information as the flame graph, but vertically, and it let's you collapse parts of it.

    ```{r, echo = FALSE}
    knitr::include_graphics(path = "./07_figs/profvis_data.png")
    ```
    
- If you see `<GC>` in in the profile, then this stands for "Garbage Collection" and is a sign that you are making lots and lots of copies that are being garbage collected. E.g.

    ```{r, eval = FALSE}
    f <- function() {
      x <- integer()
      for (i in 1:1e4) {
        x <- c(x, i)
      }
    }
    profvis(f())
    ```

    ```{r, echo = FALSE}
    knitr::include_graphics(path = "./07_figs/profvis_gc.png")
    ```

- The line where the issue occurs can be seen in the memory column.

- To profile an R package, just load it into memory via `devtools::load_all()`, then run `profvis()` using code from that package on some example data.

## Notes

- You cannot profile C/C++ code using `{profvis}`. You would have to use a C++ profiler like [gperftools](https://github.com/gperftools/gperftools). More information can be found in [Section 3.4 of Writing R Extensions](https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Profiling-compiled-code).

- Using anonymous functions will make the results of `{profvis}` confusing.

- The results are are a statistical sample of your call stack (what is being run and its ancestors), so your results will differ. But this only matters for really fast functions, which aren't the ones you care about.

## Exercise

Here is a crappy implementation of fitting a linear model:

```{r}
lmsuck <- function(x, y) {
  x <- cbind(1, x)
  betahat <- c(solve(t(x) %*% x) %*% t(x) %*% y)
  names(betahat) <- c("beta0", "beta1")
  fits <- c(x %*% betahat)
  resids <- y - fits
  sigma <- sqrt(sum(resids^2) / (nrow(x) - ncol(x)))
  return(list(betahat = betahat, 
              sigma = sigma, 
              fits = fits, 
              resids = resids, 
              x = x, 
              y = y))
}
```

It seems to give similar results:

```{r}
lm_sout <- lmsuck(x = mtcars$wt, y = mtcars$mpg)
lm_g <- lm(mpg ~ wt, data = mtcars)

lm_sout$betahat
coef(lm_g)

lm_sout$sigma
sigma(lm_g)
```

Profile `lmsuck()` on a large ($n \geq 100000$) simulated dataset and tell me what takes the longest.

```{r, eval = FALSE, echo = FALSE}
n <- 1000000
x <- runif(n)
beta0 <- 0
beta1 <- 2
y <- beta0 + beta1 * x + rnorm(n)
profvis::profvis(lmsuck(x = x, y = y)) 
## Matrix multiplication takes the longest
```

# Microbenchmarking

- Benchmarking will compare small pieces of code.

- This is only useful if you are using this code thousands of times a second.

- Don't try to generalize small fast code with slower versions (i.g. knowing what's faster when $n=1$ tells you nothing about what's faster when $n = 10000000$).

- Use `bench::mark()` to do microbenchmarking.

    ```{r}
    rsum <- function(x) {
      sval <- 0
      for (i in seq_along(x)) {
        sval <- x[[i]] + sval
      }
      return(sval)
    }
    
    x <- 1:100
    lb <- bench::mark(
      sum(x),
      rsum(x)
    )
    lb
    ```

    So running `sum()` a million times would take about 0.2 seconds. Running `rsum()` a million times would take about 5 seconds.
    
    But rarly do you need to run `sum()` a million times, so typically either one is OK in real life.

- Always pay attention to the units. 1 ms $>$ 1 µs $>$ 1 ns.
    - 1 ms, then one thousand calls take a second.
    - 1 µs, then one million calls take a second.
    - 1 ns, then one billion calls take a second.

- There is a nice plot method for `bench_mark` objects (multimodality comes from other processes running in the background).

    ```{r, message = FALSE}
    plot(lb)
    ```
    
## Exercise

For summing up the columns of a matrix, I can think of at least four ways

1. `colSums()`
2. Matrix multiplication on the left by a vector of `1`'s
3. Using a for-loop on the columns, calculating the sum each time.
4. Using functional programming with `apply()`.

Create functions that implements all four of these approaches and tell me which one is the fastest for $100\times 100$, $1000\times 100$, and $100\times 1000$ matrices.

```{r, eval = FALSE, echo = FALSE}
f_colsum <- function(A) {
  return(colSums(A))
}

f_mult <- function(A) {
  return(c(matrix(1, nrow = 1, ncol = nrow(A)) %*% A))
}

f_loop <- function(A) {
  svec <- rep(NA_real_, length.out = ncol(A))
  for (i in seq_len(ncol(A))) {
    svec[[i]] <- sum(A[, i])
  }
  return(svec)
}

f_apply <- function(A) {
  return(apply(X = A, MARGIN = 2, FUN = sum))
}

A <- matrix(runif(25), ncol = 5, nrow = 5)
s1 <- f_colsum(A)
s2 <- f_mult(A)
s3 <- f_loop(A)
s4 <- f_apply(A)
stopifnot(s1 == s2, s1 == s3, s1 == s4)

A <- matrix(runif(10000), nrow = 100, ncol = 100)
bench::mark(
  f_colsum(A),
  f_mult(A),
  f_loop(A),
  f_apply(A)
)

A <- matrix(runif(10000), nrow = 100, ncol = 1000)
bench::mark(
  f_colsum(A),
  f_mult(A),
  f_loop(A),
  f_apply(A)
)

A <- matrix(runif(10000), nrow = 1000, ncol = 100)
bench::mark(
  f_colsum(A),
  f_mult(A),
  f_loop(A),
  f_apply(A)
)
## 100x100: matrix mult and colSum work about the same in terms of speed
## 100x1000: Again, mult and colSum work about the same in terms of speed
## 1000x100: Matrix multiplication works a little better
## For loops and apply are always the worst
## matrix mult uses more memory in all scenarios than colSums
```

# New Functions

- `profvis::profvis()`: Profile a function.
- `bench::mark()`: Microbenchmark multiple expressions.

# References
