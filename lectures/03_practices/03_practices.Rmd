---
title: "Software Development Best Practices"
author: "David Gerard"
date: "`r Sys.Date()`"
output:  
  html_document:
    toc: true
    toc_depth: 4
    toc_float: false
    highlight: pygments
urlcolor: "blue"
---

```{r setup, include=FALSE}
set.seed(1)
knitr::opts_chunk$set(echo       = TRUE, 
                      fig.align  = "center",
                      fig.height = 3, 
                      fig.width  = 4)
knitr::opts_knit$set(global.par = TRUE)
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
par(mar = c(3, 3, 2, 1),
mgp = c(1.8, 0.4, 0), 
las = 1,
tcl = -.25)
```

# Learning Objectives

- Assertions
- Unit Tests
- Package Checking
- Coding Style
- Chapters 12 and 19 from [R Packages](https://r-pkgs.org/index.html)
- [The tidyverse style guide](https://style.tidyverse.org/)

# A Working Example

- For this lecture, let's suppose that we want to create a package to simulate data from the normal simple linear regression model.

- Recall that the normal simple linear regression model is of the form
    \begin{align}
    Y_i &= \beta_0 + \beta_1X_i + \epsilon_i\\
    \epsilon_i &\sim N(0,\sigma^2)
    \end{align}

- Here, 
    - $Y_i$ is the value of the response variable for obsrvation $i$.
    - $X_i$ is the value of the predigor variable for obsrevation $i$.
    - $\beta_0$ is the $y$-intercept, 
    - $\beta_1$ is the slope (values that are 1 $x$ larger tend to be $\beta_1$ $y$ larger, on average).
    - $\epsilon_i$ is the error for observation $i$. Assumed to be a random variable with a normal distribution with mean 0 and variance $\sigma^2$.
    
- If we had the $X_i$'s, $\beta_0$, $\beta_1$, $\sigma^2$, and the sample size $n$, then it would be easy to simulate under this model.
    ```{r}
    n <- 100
    sigma2 <- 0.1
    beta0 <- 0
    beta1 <- 2
    x <- runif(n)
    eps <- rnorm(n, mean = 0, sd = sqrt(sigma2))
    y <- beta0 + beta1 * x + eps
    
    plot(x, y)
    abline(a = beta0, b = beta1, col = 2)
    grid()
    ```

    
- There are many design considerations for simulating under this model:
    1. Do we simulate the $X$'s or do we obtain these values from the user? If we simulate them, how do we do this? Should we allow the user to do both?
    2. Do we simulate $\beta_0$ and $\beta_1$? Do we allow the user to input a distribution for these effect sizes?
    3. Do we simulate $\sigma^2$? This is often difficult for the user to choose, so maybe there is a more intuitive specification for it?
    
- Let's start with a basic function where we assume the user has provided everything. We'll expand on this later.

    ```{r}
    #' @title Simulate SLR
    #' 
    #' @description Simulate response values from the normal simple
    #'     linear regression model.
    #' 
    #' @param n The sample size
    #' @param x The values of the predictor variable for the \code{n}
    #'    individuals. 
    #' @param beta0 The y-intercept.
    #' @param beta1 The slope.
    #' @param sigma2 The error variance.
    #' 
    #' @return A vector of length n. The values of the response variable.
    #' 
    #' @author David Gerard
    #' 
    #' @examples
    #' n <- 100
    #' x <- runif(n)
    #' beta0 <- 0
    #' beta1 <- 2
    #' sigma2 <- 0.5
    #' y <- simreg(n = n, x = x, beta0 = beta0, beta1 = beta1, sigma2 = sigma2)
    #' plot(x, y)
    #' abline(a = beta0, b = beta1)
    simreg <- function(n, x, beta0, beta1, sigma2) {
      eps <- stats::rnorm(n = n, mean = 0, sd = sqrt(sigma2))
      y <- beta0 + beta1 * x + eps
      return(y)
    }
    ```


# Assertions

- One hallmark of good programming is to return an error as early as possible.

- For example, what if the user provided an incorrect input
    ```{r}
    n <- 100
    sigma2 <- 0.1
    beta0 <- 0
    beta1 <- 2
    x <- runif(n)
    y <- simreg(n = 1, x = x, beta0 = beta0, beta1 = beta1, sigma2 = sigma2)
    ```
    It ran OK, but there was no error even though `n = 100`. What gives? Let's look at a plot.
    ```{r}
    plot(x, y)
    ```
    So R is recycling the one error term that it simulated. It would be nice to catch this so that it doesn't hurt a user down the road.

- An **assertion** is a statement during your code that should always evaluation to `TRUE`. If an assertion evaluates to `FALSE` then this throws an error.

- In R, the base assertion is `stopifnot()`.

    ```{r, error=TRUE}
    x <- 10
    stopifnot(x == 10)
    stopifnot(x > 20)
    ```

- If you want to be more explicit about your errors, you can put `stop()` inside an if-then statement.

    ```{r, error=TRUE}
    if (x != 10) {
      stop("x is not 10")
    }
    ```

- For user-facing functions, I like to check user arguments for validity in R.
    - Other languages force argument validity, but R, e.g., allows users to insert characters for numeric arguments!
    
- Let's try this out for `simreg()`.

    ```{r}
    simreg <- function(n, x, beta0, beta1, sigma2) {
      ## Check input
      stopifnot(length(x) == n)
      
      ## Simulate y
      eps <- stats::rnorm(n = n, mean = 0, sd = sqrt(sigma2))
      y <- beta0 + beta1 * x + eps
      return(y)
    }
    ```
    
- Then we get an error that tells us we made a mistake. This could save a user a huge amount of debugging time down the road.
    ```{r, error=TRUE}
    y <- simreg(n = 1, x = x, beta0 = beta0, beta1 = beta1, sigma2 = sigma2)
    ```

- If you just don't like the behavior, but don't want to kill the program, use `warning()`.

    ```{r, warning=TRUE}
    simreg <- function(n, x, beta0, beta1, sigma2) {
      ## Check input
      if (length(x) != n) {
        warning("n not equal to length(x). Recycling error terms.")
      }
      
      ## Simulate y
      eps <- stats::rnorm(n = n, mean = 0, sd = sqrt(sigma2))
      y <- beta0 + beta1 * x + eps
      return(y)
    }
    y <- simreg(n = 1, x = x, beta0 = beta0, beta1 = beta1, sigma2 = sigma2)
    ```

- **Exercise**: Add assertions to check:
    1. That `n`, `beta0`, `beta1`, and `sigma2` are all length 1.
    2. That all of the variables are numerics.
    3. That `sigma2` is non-negative.
    
    ```{r, eval = FALSE, echo = FALSE}
    simreg <- function(n, x, beta0, beta1, sigma2) {
      ## Check input
      stopifnot(length(x) == n)
      stopifnot(length(n) == 1, 
                length(beta0) == 1, 
                length(beta1) == 1, 
                length(sigma2) == 1)
      stopifnot(sigma2 >= 0)
      stopifnot(is.numeric(n),
                is.numeric(x),
                is.numeric(beta0),
                is.numeric(beta1),
                is.numeric(sigma2))
      
      ## Simulate y
      eps <- stats::rnorm(n = n, mean = 0, sd = sqrt(sigma2))
      y <- beta0 + beta1 * x + eps
      return(y)
    }
    y <- simreg(n = 100, x = x, beta0 = beta0, beta1 = beta1, sigma2 = sigma2)
    ```
    
- You should also place assertions in the middle of code (not just checking user inputs) in cases where you want to be doubly sure that your code is working.

- E.g. I often place an assertion during optimization scripts to make sure that the objective function is not decreasing each iteration.

# Unit Tests

- So far your work flow has been to iteratively:
    1. Write a function.
    2. Load the package into memory with `devtools::load_all()`
    3. Play around with it, testing it on your own.
    
- This is great, but informal. If your code changes, those informal checks you ran might no longer work, and you wouldn't know.

- A **unit test** is a stored test that you can rerun automatically.

- Your workflow when coding using unit tests is to:
    1. Modify code or tests.
    2. Test package with `devtools::test()`. This will run all unit tests.
    3. Repeat until all tests pass.

- Writing unit tests is a fair amount of work but it is worth it because:
    1. If your code changes in a breaking way, your unit tests will alert you. This makes you more confident to make robust changes to your code.
    2. I often find bugs while I create unit tests. Describing what I expect and testing out corner cases formally lowers the chance of a bug ending up in your final product.

- `{testthat}` is one of the R package that implements unit tests in R. The second most popular one is probably `{RUnit}`.

    ```{r}
    library(testthat)
    local_edition(3)
    ```

- To use `{testthat}`, run
    ```{r, eval=FALSE}
    usethis::use_testthat()
    ```

- This will have created a new folder "tests". Inside this folder is an R script "testthat.R" and another folder "testthat".

    ```
    .
    ├── DESCRIPTION
    ├── NAMESPACE
    ├── R
    └── tests
        ├── testthat
        └── testthat.R
    ```
    
- "testthat.R" contains a few lines of code telling R to run all of your unit tests during package checking.

- Unit tests will be in R scripts inside the "testthat" folder.
    
- **Expectation**: Describes expected result of a computation. 
    - Correct value? 
    - Correct type (character/numeric/factor/logical)? 
    - Correctly produces an error when expected?
    - All expectations are functions like `expect_*()`
    
- **Test**: A group of related expectations. Usually, a test tests only one function, or a couple tightly related functions. A test is created with `test_that()`.

- **Testthat File**: A collection of related tests.

## Testthat File

- A testthat file is just an R script that holds a few related tests.

- You can create an R script for unit testing by typing
    ```{r, eval=FALSE}
    usethis::use_test()
    ```
    specifying the `name` of the R script.
    
## Test

- All `{testthat}` tests are of the form

    ```{r, eval=FALSE}
    test_that("Human Readable Description", {
      ## Code running test
    })
    ```

## Expectation

- An expectation returns an error if a function or result is not what you expect.

- In `{testthat}` all expectations begin with `expect_`.

- The first argument is the actual result of a function in your package. The second argument is the expected result.

- The most common expectation is to test for equality with `expect_equal()`.
    ```{r}
    x <- 10
    y <- 10
    expect_equal(x, y)
    ```
    You can specify the tolerance level so for items that are only approximately equal
    ```{r, error=TRUE}
    expect_equal(10, 10 + 10^-8)
    expect_equal(10, 10 + 10^-5)
    expect_equal(10, 10 + 10^-5, tolerance = 10^-4)
    ```
- Use `ignore_attr = TRUE` if your objects have different attributes and you just care about the numeric values (default `expect_equal()` will throw an error):
    ```{r, error=TRUE}
    local_edition(3) ## not necessary for package
    names(x) <- "hello"
    expect_equal(x, y)
    expect_equal(x, y, ignore_attr = TRUE)
    ```
    
- The `local_edition(3)` code makes it so my code chunks use the most recent `{testthat}` functions. You don't need to worry about that in your package. `{usethis}` will automatically assume the third edition. You can explicitely use the third edition by adding the following to your DESCRIPTION file:
    ```{yaml, eval = FALSE}
    Config/testthat/edition: 3
    ```

- `expect_match()` checks for a regular expression match.

    ```{r, error = TRUE}
    expect_match("hello", "ll")
    expect_match("helo", "ll")
    ```

- You can use `expect_warning()` and `expect_error()` to check that your functions error correctly.

    ```{r}
    simreg <- function(n, x, beta0, beta1, sigma2) {
      ## Check input
      stopifnot(length(x) == n)
      
      ## Simulate y
      eps <- stats::rnorm(n = n, mean = 0, sd = sqrt(sigma2))
      y <- beta0 + beta1 * x + eps
      return(y)
    }
    
    x <- runif(100)
    beta0 <- 0
    beta1 <- 2
    sigma2 <- 0.5
    expect_error(simreg(n = 1, 
                        x = x, 
                        beta0 = beta0, 
                        beta1 = beta1, 
                        sigma2 = sigma2))
    ```
    
- It is recommended that you think harder about your unit tests, but you can just test for a non-error by using `expect_error()` and setting `regexp = NA`
    ```{r}
    expect_error(simreg(n = length(x), 
                        x = x, 
                        beta0 = beta0, 
                        beta1 = beta1, 
                        sigma2 = sigma2), 
                 regexp = NA)
    ```

- `expect_type()` is tests for the type of the output (`"double"`, `"integer"`, `"character"`, or `"logical"`).
    ```{r}
    local_edition(3)
    expect_type(1, "double")
    expect_type(1L, "integer")
    expect_type("1", "character")
    expect_type(TRUE, "logical")
    ```

- `expect_s3_class()` is used to test for the class of the object (e.g. `"data.frame"`, `"matrix"`, `"tibble"`, `"lm"`, etc..)
    ```{r}
    y <- simreg(n = length(x), x = x, beta0 = beta0, beta1 = beta1, sigma2 = sigma2)
    lmout <- lout <- lm(y ~ x)
    expect_s3_class(object = lmout, class = "lm")
    ```

- `expect_true()` acts like `stopifnot()` except for unit tests instead of assertions.
    ```{r}
    expect_true(3 == 3)
    ```


# Package Checking

- Don't include non-ASCII characters in your code. This will give you a CRAN note.

- If you accidentally include such characters, you can find them with
    ```{r, eval = FALSE}
    tools::showNonASCIIfile()
    ```
    
## Continuous Integration

# Coding Style

- You should break up your functions into discrete tasks.
    - Reduces duplicating code, so less prone to bugs.
    - Allows you to think more modularly about tasks, which makes code easier to reason about.
    - Makes it easier to combine code in new ways.

- One way to force you to do this is to make all functions be less than some length. E.g. Bioconductor recommends having [no functions longer than 50 lines](https://bioconductor.org/packages/devel/bioc/vignettes/BiocCheck/inst/doc/BiocCheck.html#function-length-checking).

